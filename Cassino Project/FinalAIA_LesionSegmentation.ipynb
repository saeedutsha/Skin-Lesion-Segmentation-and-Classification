{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1e1_s_p026D0X2Z9IFu_mWfRGDS_1xC7A","timestamp":1655716231588},{"file_id":"178SRbNjeWsF_PzsddWG9YfT1Gvk9gy52","timestamp":1651868528194}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Datset Loading**"],"metadata":{"id":"j_WH54bAkpFt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2wQKoJk8xw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655677658663,"user_tz":-120,"elapsed":21216,"user":{"displayName":"Jose Carlos Reyes Hernandez","userId":"03583105795035359437"}},"outputId":"5c34f2f4-2e7d-4463-a487-658562daf48c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["#Connecting the cloud to download the images\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["#Importing the required libraries\n","import os\n","import numpy as np\n","import cv2\n","from glob import glob\n","from google.colab.patches import cv2_imshow\n","from scipy.ndimage import gaussian_filter\n","from scipy.ndimage.filters import median_filter\n","from skimage.morphology import disk\n","from skimage import color\n","import pickle as pkl\n","from sklearn.metrics import jaccard_score\n","from sklearn.cluster import KMeans\n","from scipy import ndimage\n","from skimage.morphology import remove_small_objects\n","import matplotlib.pyplot as plt"],"metadata":{"id":"BVXLDUOlp1NQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def load_data(path):\n","\n","    train_x = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/Colab Notebooks/ISIC/images\", \"*.jpg\")))\n","    masks = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/Colab Notebooks/ISIC/masks\", \"*.png\")))\n","\n","    return train_x, masks"],"metadata":{"id":"qXfaSmJcpbHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oTIveNGUdA1-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655677710024,"user_tz":-120,"elapsed":453,"user":{"displayName":"Jose Carlos Reyes Hernandez","userId":"03583105795035359437"}},"outputId":"b61cb940-eb1e-48cb-8949-5dae1dd45cc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 200\n"]}],"source":["#Loading the original training images and masks\n","if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)\n","\n","    \"\"\" Load the data \"\"\"\n","    data_path = \"/content/drive/MyDrive/Colab Notebooks/ISIC\"\n","    (train_x, masks) = load_data(data_path)\n","\n","    print(f\"Train: {len(train_x)}\")\n","    "]},{"cell_type":"markdown","source":["**Preprocessing with Hair Removal**"],"metadata":{"id":"6WvaOSTZkEV4"}},{"cell_type":"code","source":["######## Create Rotating and Tilted Structuring Element ##########\n","def createTiltedStructuringElements(width, height, n):\n","  # width = 11\n","  # height = 1\n","  # n = 30\n","  base = np.zeros((width, width), np.uint8)\n","  start = int(width/2-height/2)\n","  end = int(width/2+height/2)\n","  for k in range(start+1, end+1):\n","    cv2.line(base,(0,k),(width,k),(255,255,255))\n","  SE_list = []\n","  SE_list.append(base)\n","  angle_step = 360.0/n\n","  for i in range(n):\n","    rows = base.shape[0]\n","    cols = base.shape[1]\n","    M = cv2.getRotationMatrix2D((cols/2.0, rows/2.0), i*angle_step, 1.0)\n","    SE = cv2.warpAffine(base, M, (width, width),  cv2.INTER_NEAREST);\n","    SE_list.append(SE)\n","  return SE_list"],"metadata":{"id":"yeu_Ds1HLy9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creating a function for removing the hairs\n","def image_preprocessing(src_image, SE_list):\n","  \n","  #Removing noise from the image\n","  median_image = median_filter(src_image, 3)\n","  #Converting to grayscale for appling gs morphology\n","  gray_image = cv2.cvtColor(median_image, cv2.COLOR_BGR2GRAY)\n","  #Inverting the intentisities of the pixels before using tophat transform\n","  inv_image = cv2.bitwise_not(gray_image)\n","  #Defining a matrix to store the sum of tophats\n","  sumOfTopHats = np.zeros((inv_image.shape[0], inv_image.shape[1]), np.uint16)\n","\n","  #Applying a sum of tophat transform with different rotated SE to the images\n","  for SE in SE_list:\n","    tophat_image = cv2.morphologyEx(inv_image, cv2.MORPH_TOPHAT, SE)\n","    tophat_image = np.uint16(tophat_image)\n","    sumOfTopHats += tophat_image\n","  #Normalizing the intensities values of the pixels\n","  cv2.normalize(sumOfTopHats, sumOfTopHats, 0, 255, cv2.NORM_MINMAX);\n","  #Converting back to uint8 for visualization\n","  sumOfTopHats = np.uint8(sumOfTopHats)\n","  #Changing againg the pixels intensities before thresholding\n","  inv_tophat = cv2.bitwise_not(sumOfTopHats)\n","  #Thresholding the image to create a mask\n","  ret, thres_image = cv2.threshold(sumOfTopHats, 10, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","  #Applying morphological operations for removing remaining dark objects\n","  disk_kernel = disk(5)\n","  closed_image1 = cv2.morphologyEx(thres_image, cv2.MORPH_CLOSE, disk_kernel)\n","  # dil_kernel = disk(5)\n","  dil_kernel = np.ones((3,3),np.uint8)\n","  dilation_image = cv2.dilate(closed_image1,dil_kernel,iterations = 1)\n","\n","  #Inpainting with the dilated mask for removing remaining dark objects\n","  inpainted_image = cv2.inpaint(src_image,dilation_image,20,cv2.INPAINT_TELEA)\n","\n","  return inpainted_image"],"metadata":{"id":"hj-wImJTkHlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Defining a circular mask for the FOV removal algorithm\n","def create_circular_mask(h, w, center, radius):\n","    Y, X = np.ogrid[:h, :w]\n","    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n","    mask = dist_from_center <= radius\n","    return mask"],"metadata":{"id":"jT-EM_a9DJtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Defining a function for FOV removal\n","def remove_black_border(inp_image):\n","  with_border_img = inp_image\n","  #Defining the size of the circular mask\n","  h, w = with_border_img.shape[:2]\n","  center = (int(w/2), int(h/2))\n","  radius = min(center[0], center[1], w-center[0], h-center[1])\n","  mask = create_circular_mask(h,w,center,radius)\n","  masked_img =  with_border_img.copy()\n","  #Counting the pixels intensities\n","  count_black = np.count_nonzero(masked_img[~mask] < 50)\n","  count_white = np.count_nonzero(masked_img[~mask] >= 50)\n","  count_total = count_black + count_white\n","  check = count_black/count_total*100\n","  diff = 100\n","  #Setting a condition for identifying whether there is a FOV in the image\n","  if(check<10):\n","    return inp_image\n","  else:\n","  #Counting the intensities values of the pixels and subtracting the circular mask from the original image\n","  #until there is no more black ring. \n","    while diff>10:\n","      radius = radius-20 #The radius is reduced on each iteration to subtract remaining black pixels\n","      mask = create_circular_mask(h,w,center,radius)\n","      #Initial pixels intensities values on each iteration\n","      old_black = count_black\n","      old_white = count_white\n","      old_total = count_total\n","      #Counting the intensities values on each iteration\n","      count_black = np.count_nonzero(masked_img[~mask] < 50)\n","      count_white = np.count_nonzero(masked_img[~mask] >= 50)\n","      count_total = count_black + count_white\n","      #Checking if the stopping condition is met\n","      diff_black = abs(count_black-old_black)\n","      diff_white = abs(count_white-old_white)\n","      diff_total = abs(count_total-old_total)\n","      diff = diff_black/(diff_total+1)*100\n","  masked_img[~mask] = 185\n","  return  masked_img\n"],"metadata":{"id":"96rPbt3JNfxB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**K-Means Clustering**"],"metadata":{"id":"0Gc-Ep1C__Rb"}},{"cell_type":"code","source":["def kmeans(prep_img):\n","  #Converting to RGB\n","  newRGB=cv2.cvtColor(prep_img,cv2.COLOR_BGR2RGB)\n","  \n","  \n","  #Flattening our image from 3D to 2D ((w*h),RGB)\n","  flat_img=newRGB.reshape((-1,3))\n","\n","  #Converting to float values\n","  flat_img=np.float32(flat_img)\n","  #print(flat_img.shape)\n","\n","  #Define stopping criteria (either i>100 or k<e=0.2)\n","  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n","\n","  # number of clusters (k)\n","  k = 2\n","\n","  #labels = cluster label for each pixel (up to k)/ center points\n","  ret, labels, centers = cv2.kmeans(flat_img, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n","\n","  #Back to uint8\n","  centers = np.uint8(centers)\n","\n","  #median_filter\n","  centers = median_filter(centers, 3)  \n","\n","  #flatten labels\n","  labels = labels.flatten()\n","\n","  #All pixels to color of the centers\n","  segmented_img = centers[labels.flatten()]\n","\n","  #Back to the original img dim\n","  segmented_img=segmented_img.reshape(prep_img.shape)\n","  \n","  #Converting to Grayscale before thresholding\n","  GS_seg=cv2.cvtColor(segmented_img,cv2.COLOR_RGB2GRAY)\n","\n","  #Creating a binary mask\n","  ret,otsu_img=cv2.threshold(GS_seg,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","\n","\n","  return otsu_img"],"metadata":{"id":"N6EBAg72AYj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def image_segmentation(inpainted_image):\n","  \n","  # ms_image = cv2.pyrMeanShiftFiltering(inpainted_image, 10, 30, 0)\n","  ms_image = inpainted_image\n","\n","  km_image = kmeans(ms_image)\n","  # if flag_border==1:\n","  #   img = km_image\n","  #   kernel = np.ones((3,3),np.uint8)\n","  #   marker = img.copy()\n","  #   marker[1:-1,1:-1]=0\n","  #   while True:\n","  #       tmp=marker.copy()\n","  #       marker=cv2.dilate(marker, kernel)\n","  #       marker=cv2.min(img, marker)\n","  #       difference = cv2.subtract(marker, tmp)\n","  #       if cv2.countNonZero(difference) == 0:\n","  #           break\n","\n","  #   mask=cv2.bitwise_not(marker)\n","  #   out=cv2.bitwise_and(img, mask)\n","  #   return out\n","  # else:\n","  return km_image\n","   \n"],"metadata":{"id":"_4RGUjwyAKY6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Post-Processing*"],"metadata":{"id":"PqpmELQofdy_"}},{"cell_type":"code","source":["#Defining a function for extranting the largest connected component\n","def extract_largest_component(image):\n","  #Searching for contours (connected componets, shapes) on the images\n","  contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","  if len(contours)==0:Â #If there is no contours, it means that the image is completely black\n","    contour_image= image \n","  else:\n","    #Calculating the area of all the contours \n","    areas= [cv2.contourArea(i) for i in contours]\n","    #Extracting the shape with the largest area\n","    largest_contour_idx= areas.index(max(areas))\n","    #Creating a temporaty black image\n","    black_image= np.zeros_like(image,np.uint8)\n","    #Printing the extracted shape (largest connected component) on the black image.\n","    contour_image= cv2.drawContours(black_image,contours,largest_contour_idx,(255,255,255),-1)\n","  return contour_image"],"metadata":{"id":"s_BRfNj6Uh3Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**WorkFlow**"],"metadata":{"id":"TR19Kg0PneIc"}},{"cell_type":"code","source":["#Rezising the training images and masks\n","X_train = []\n","X_masks = []\n","for data in train_x:\n","  image = cv2.imread(data)\n","  # print('Original Dimensions : ',img.shape)\n","  dim = (256, 256)\n","  # resize image\n","  resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n","  X_train.append(resized)\n","\n","for data in masks:\n","  image = cv2.imread(data)\n","  # print('Original Dimensions : ',img.shape)\n","  dim = (256, 256)\n","  # resize image\n","  resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n","  X_masks.append(resized)"],"metadata":{"id":"IQDm_8-0uDVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Creating Tilted Structuring Element for sum of TopHats\n","SE_list = []\n","SE_list = createTiltedStructuringElements(11, 1, 40)"],"metadata":{"id":"9ZlQtzLubz6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Pre-processing: hair removal\n","preprocessed_image = []\n","for data in X_train:\n","  image = image_preprocessing(data, SE_list)\n","  preprocessed_image.append(image)"],"metadata":{"id":"wecRyv4hnkTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessed_image = np.load('/content/drive/MyDrive/Colab Notebooks/ISIC 2017/Results/preprocessed_images_200.npy')"],"metadata":{"id":"rqyWJKAm7iXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Removing the FOV, segmenting the image and extrating the largest connected component.\n","segmented_image = []\n","for data in preprocessed_image:\n","  clean_img = remove_black_border(data)\n","  seg_img = image_segmentation(clean_img)\n","  conn_img = extract_largest_component(seg_img)\n","  segmented_image.append(conn_img)"],"metadata":{"id":"1ylwmaaUAvqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Change the FILE Name"],"metadata":{"id":"xwnef6zIfNWa"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Colab Notebooks/ISIC/preprocessed_images_train_256.npy', 'wb') as f:\n","    np.save(f, preprocessed_image)"],"metadata":{"id":"dybZ_LOYEWMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Colab Notebooks/ISIC/segmented_images_train_256.npy', 'wb') as f:\n","    np.save(f, segmented_image)"],"metadata":{"id":"gtHIw-PfBArd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Jaccard and Dice Score**"],"metadata":{"id":"ad4gzdeD3G1H"}},{"cell_type":"code","source":["#Defining a JC function to evaluate the masks generated.\n","def jaccard(im1, im2, empty_score=1.0):\n","    im1 = np.asarray(im1).astype(bool)\n","    im2 = np.asarray(im2).astype(bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    im_sum = im1.sum() + im2.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","    union = np.logical_or(im1, im2)\n","\n","    return intersection.sum() / float(union.sum())"],"metadata":{"id":"oVn_a8m_PK4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Defining a DSC function to evaluate the masks generated.\n","def dice(im1, im2, empty_score=1.0):\n","    im1 = np.asarray(im1).astype(np.bool)\n","    im2 = np.asarray(im2).astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    im_sum = im1.sum() + im2.sum()\n","    if im_sum == 0:\n","        return empty_score\n","\n","    # Compute Dice coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return 2. * intersection.sum() / im_sum"],"metadata":{"id":"rx_Dkb-A6-bu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluating the handcrafted binary masks.\n","#segmented_image= np.load('/content/drive/MyDrive/Colab Notebooks/ISIC/preprocessed_images.npy')\n","jaccard_list = []\n","dice_list = []\n","for i in range(len(segmented_image)):\n","  gray_masks = cv2.cvtColor(X_masks[i], cv2.COLOR_BGR2GRAY)\n","  image = segmented_image[i]\n","  # print(i)\n","  # cv2_imshow(X_train[i])\n","  # cv2_imshow(image)\n","  # cv2_imshow(gray_masks)\n","  # score = jaccard_score(gray_masks.flatten(), image.flatten(), average='micro')\n","  score = jaccard(image,gray_masks)\n","  dice_score = dice(image, gray_masks)\n","  # print(score)\n","  jaccard_list.append(score)\n","  dice_list.append(dice_score)\n","avg = np.mean(jaccard_list)\n","avg_dice = np.mean(dice_list)\n","print(avg)\n","print(avg_dice)"],"metadata":{"id":"EhyIyW3Cpzsi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655678453509,"user_tz":-120,"elapsed":388,"user":{"displayName":"Jose Carlos Reyes Hernandez","userId":"03583105795035359437"}},"outputId":"709f4feb-ccc4-4b81-94e2-3f6f8bc17929"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7040237282689381\n","0.8108662980882361\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]}]}