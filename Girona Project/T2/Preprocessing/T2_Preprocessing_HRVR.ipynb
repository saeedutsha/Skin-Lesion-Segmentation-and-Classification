{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Import and Install Libraries**"
      ],
      "metadata": {
        "id": "zWtQGeunt-NC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgaw6XP8Omi7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.metrics import jaccard_score\n",
        "import random\n",
        "import torch\n",
        "from sklearn import svm\n",
        "from skimage.morphology import disk\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.functional import Tensor\n",
        "from scipy.ndimage.filters import median_filter\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from scipy.stats import kurtosis, skew\n",
        "import torchvision.transforms.functional as TF\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.modules.activation import ReLU\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import kurtosis, skew\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vok0CgMAOsD8",
        "outputId": "135fd540-f7cb-42cf-e25a-bdb3324c5a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtqxOhQMhKCg"
      },
      "source": [
        "### **Preprocessing: Hair Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeu_Ds1HLy9p"
      },
      "outputs": [],
      "source": [
        "######## Create Rotating and Tilted Structuring Element ##########\n",
        "def createTiltedStructuringElements(width, height, n):\n",
        "  # width = 11\n",
        "  # height = 1\n",
        "  # n = 30\n",
        "  base = np.zeros((width, width), np.uint8)\n",
        "  start = int(width/2-height/2)\n",
        "  end = int(width/2+height/2)\n",
        "  for k in range(start+1, end+1):\n",
        "    cv2.line(base,(0,k),(width,k),(255,255,255))\n",
        "  SE_list = []\n",
        "  SE_list.append(base)\n",
        "  angle_step = 360.0/n\n",
        "  for i in range(n):\n",
        "    rows = base.shape[0]\n",
        "    cols = base.shape[1]\n",
        "    M = cv2.getRotationMatrix2D((cols/2.0, rows/2.0), i*angle_step, 1.0)\n",
        "    SE = cv2.warpAffine(base, M, (width, width),  cv2.INTER_NEAREST);\n",
        "    SE_list.append(SE)\n",
        "  return SE_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZlQtzLubz6s"
      },
      "outputs": [],
      "source": [
        "## Creating Tilted Structuring Element for sum of TopHats\n",
        "SE_list = []\n",
        "SE_list = createTiltedStructuringElements(11, 1, 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj-wImJTkHlc"
      },
      "outputs": [],
      "source": [
        "#Creating a function for removing the hairs\n",
        "def remove_hair(src_image, SE_list):\n",
        "\n",
        "  #Removing noise from the image\n",
        "  median_image = median_filter(src_image, 3)\n",
        "  #Converting to grayscale for appling gs morphology\n",
        "  gray_image = cv2.cvtColor(median_image, cv2.COLOR_BGR2GRAY)\n",
        "  #Inverting the intentisities of the pixels before using tophat transform\n",
        "  inv_image = cv2.bitwise_not(gray_image)\n",
        "  #Defining a matrix to store the sum of tophats\n",
        "  sumOfTopHats = np.zeros((inv_image.shape[0], inv_image.shape[1]), np.uint16)\n",
        "\n",
        "  #Applying a sum of tophat transform with different rotated SE to the images\n",
        "  for SE in SE_list:\n",
        "    tophat_image = cv2.morphologyEx(inv_image, cv2.MORPH_TOPHAT, SE)\n",
        "    tophat_image = np.uint16(tophat_image)\n",
        "    sumOfTopHats += tophat_image\n",
        "  #Normalizing the intensities values of the pixels\n",
        "  cv2.normalize(sumOfTopHats, sumOfTopHats, 0, 255, cv2.NORM_MINMAX);\n",
        "  #Converting back to uint8 for visualization\n",
        "  sumOfTopHats = np.uint8(sumOfTopHats)\n",
        "  #Changing againg the pixels intensities before thresholding\n",
        "  inv_tophat = cv2.bitwise_not(sumOfTopHats)\n",
        "  #Thresholding the image to create a mask\n",
        "  ret, thres_image = cv2.threshold(sumOfTopHats, 10, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "  #Applying morphological operations for removing remaining dark objects\n",
        "  disk_kernel = disk(5)\n",
        "  closed_image1 = cv2.morphologyEx(thres_image, cv2.MORPH_CLOSE, disk_kernel)\n",
        "  # dil_kernel = disk(5)\n",
        "  dil_kernel = np.ones((3,3),np.uint8)\n",
        "  dilation_image = cv2.dilate(closed_image1,dil_kernel,iterations = 1)\n",
        "\n",
        "  #Inpainting with the dilated mask for removing remaining dark objects\n",
        "  inpainted_image = cv2.inpaint(src_image,dilation_image,20,cv2.INPAINT_TELEA)\n",
        "\n",
        "  return inpainted_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S5MmF3NhylI"
      },
      "source": [
        "### **Preprocessing: Vignette Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT-EM_a9DJtB"
      },
      "outputs": [],
      "source": [
        "#Defining a circular mask for the FOV removal algorithm\n",
        "def create_circular_mask(h, w, center, radius):\n",
        "    Y, X = np.ogrid[:h, :w]\n",
        "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
        "    mask = dist_from_center <= radius\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96rPbt3JNfxB"
      },
      "outputs": [],
      "source": [
        "#Defining a function for FOV removal\n",
        "def remove_black_border(inp_image):\n",
        "  with_border_img = inp_image\n",
        "  #Defining the size of the circular mask\n",
        "  h, w = with_border_img.shape[:2]\n",
        "  center = (int(w/2), int(h/2))\n",
        "  radius = min(center[0], center[1], w-center[0], h-center[1])\n",
        "  mask = create_circular_mask(h,w,center,radius)\n",
        "  masked_img =  with_border_img.copy()\n",
        "  #Counting the pixels intensities\n",
        "  count_black = np.count_nonzero(masked_img[~mask] < 50)\n",
        "  count_white = np.count_nonzero(masked_img[~mask] >= 50)\n",
        "  count_total = count_black + count_white\n",
        "  check = count_black/count_total*100\n",
        "  diff = 100\n",
        "  #Setting a condition for identifying whether there is a FOV in the image\n",
        "  if(check<10):\n",
        "    return inp_image\n",
        "  else:\n",
        "  #Counting the intensities values of the pixels and subtracting the circular mask from the original image\n",
        "  #until there is no more black ring. \n",
        "    while diff>10:\n",
        "      radius = radius-8 #The radius is reduced on each iteration to subtract remaining black pixels\n",
        "      mask = create_circular_mask(h,w,center,radius)\n",
        "      #Initial pixels intensities values on each iteration\n",
        "      old_black = count_black\n",
        "      old_white = count_white\n",
        "      old_total = count_total\n",
        "      #Counting the intensities values on each iteration\n",
        "      count_black = np.count_nonzero(masked_img[~mask] < 50)\n",
        "      count_white = np.count_nonzero(masked_img[~mask] >= 50)\n",
        "      count_total = count_black + count_white\n",
        "      #Checking if the stopping condition is met\n",
        "      diff_black = abs(count_black-old_black)\n",
        "      diff_white = abs(count_white-old_white)\n",
        "      diff_total = abs(count_total-old_total)\n",
        "      diff = diff_black/(diff_total+1)*100\n",
        "  masked_img[~mask] = 255\n",
        "  return  masked_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Loading**"
      ],
      "metadata": {
        "id": "TUpsmg4IuGwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories\n",
        "input_directory = '/content/gdrive/MyDrive/Colab Notebooks/CAD Project/Dataset/Three Class Problem'\n",
        "pp_directory = '/content/gdrive/MyDrive/Colab Notebooks/CAD Project/Dataset/Three Class Problem Preprocessed'\n",
        "train_directory = input_directory+'/train' \n",
        "val_directory = input_directory+'/val'\n",
        "pp_train_directory = pp_directory+'/train' \n",
        "pp_val_directory = pp_directory+'/val'"
      ],
      "metadata": {
        "id": "l5F_5rm4OuN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training set organization\n",
        "train_bcc= sorted(glob(os.path.join(train_directory, \"bcc\", \"*.jpg\")))\n",
        "train_mel= sorted(glob(os.path.join(train_directory, \"mel\", \"*.jpg\")))\n",
        "train_scc= sorted(glob(os.path.join(train_directory, \"scc\", \"*.jpg\")))\n",
        "tags_bcc_train=[]\n",
        "tags_mel_train=[]\n",
        "tags_scc_train=[]\n",
        "tags_train=[]\n",
        "images_bcc=[]\n",
        "images_mel=[]\n",
        "images_scc=[]\n",
        "labels_bcc=[]\n",
        "labels_mel=[]\n",
        "labels_scc=[]"
      ],
      "metadata": {
        "id": "NZZ27mV6O64b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validation set organization\n",
        "train_bcc_val= sorted(glob(os.path.join(val_directory, \"bcc\", \"*.jpg\")))\n",
        "train_mel_val= sorted(glob(os.path.join(val_directory, \"mel\", \"*.jpg\")))\n",
        "train_scc_val= sorted(glob(os.path.join(val_directory, \"scc\", \"*.jpg\")))\n",
        "tags_bcc_val=[]\n",
        "tags_mel_val=[]\n",
        "tags_scc_val=[]\n",
        "tags_val=[]\n",
        "images_bcc_val=[]\n",
        "images_mel_val=[]\n",
        "images_scc_val=[]\n",
        "labels_bcc_val=[]\n",
        "labels_mel_val=[]\n",
        "labels_scc_val=[]"
      ],
      "metadata": {
        "id": "s0MpkkXiO8Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_mel))\n",
        "print(len(train_bcc))\n",
        "print(len(train_scc))\n",
        "print(len(train_bcc_val))\n",
        "print(len(train_mel_val))\n",
        "print(len(train_scc_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nacx2uy2PJ77",
        "outputId": "53a260d4-5d1b-4083-b4fe-2d818e4896e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2713\n",
            "2713\n",
            "2632\n",
            "498\n",
            "678\n",
            "94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = (512, 512)"
      ],
      "metadata": {
        "id": "FUNFXrfNwDJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Dataframe Construction**"
      ],
      "metadata": {
        "id": "NEXwzKjUxerm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_mel)):\n",
        "  path_image = os.path.join(pp_train_directory, \"mel\", train_mel[i][-12:])\n",
        "  image_read= cv2.imread(train_mel[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_mel_train.append(train_mel[i][-12:])\n",
        "  labels_mel.append(0)"
      ],
      "metadata": {
        "id": "qMgy4YmXvquU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_bcc)):\n",
        "  path_image = os.path.join(pp_train_directory, \"bcc\", train_bcc[i][-12:])\n",
        "  image_read= cv2.imread(train_bcc[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_bcc_train.append(train_bcc[i][-12:])\n",
        "  labels_bcc.append(1)"
      ],
      "metadata": {
        "id": "mF_Mq4Q5vsb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_scc)):\n",
        "  path_image = os.path.join(pp_train_directory, \"scc\", train_scc[i][-12:])\n",
        "  image_read= cv2.imread(train_scc[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_scc_train.append(train_scc[i][-12:])\n",
        "  labels_scc.append(2)"
      ],
      "metadata": {
        "id": "oLc2nWWzvu5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation Dataframe Creation**"
      ],
      "metadata": {
        "id": "tyFe4qFTxiyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_mel_val)):\n",
        "  path_image = os.path.join(pp_val_directory, \"mel\", train_mel_val[i][-12:])\n",
        "  image_read= cv2.imread(train_mel_val[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_mel_val.append(train_mel_val[i][-12:])\n",
        "  labels_mel_val.append(0)"
      ],
      "metadata": {
        "id": "cKnGSTBIxt3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_bcc_val)):\n",
        "  path_image = os.path.join(pp_val_directory, \"bcc\", train_bcc_val[i][-12:])\n",
        "  image_read= cv2.imread(train_bcc_val[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_bcc_val.append(train_bcc_val[i][-12:])\n",
        "  labels_bcc_val.append(1)"
      ],
      "metadata": {
        "id": "C21oe6gvxt3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_scc_val)):\n",
        "  path_image = os.path.join(pp_val_directory, \"scc\", train_scc_val[i][-12:])\n",
        "  image_read= cv2.imread(train_scc_val[i])\n",
        "  image_resized =  cv2.resize(image_read, dim, interpolation = cv2.INTER_AREA)\n",
        "  image_hair_removed= remove_hair(image_resized, SE_list)\n",
        "  image_vignette_removed= remove_black_border(image_hair_removed)\n",
        "  cv2.imwrite(path_image, image_vignette_removed)\n",
        "  tags_scc_val.append(train_scc_val[i][-12:])\n",
        "  labels_scc_val.append(2)"
      ],
      "metadata": {
        "id": "viMC5jVyxt3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tags_train= tags_mel_train + tags_bcc_train + tags_scc_train\n",
        "# X_train= labels_mel+labels_bcc+labels_scc"
      ],
      "metadata": {
        "id": "3hg5yS-gPFKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_val= tags_mel_val + tags_bcc_val+tags_scc_val\n",
        "X_test= labels_mel_val +labels_bcc_val+labels_scc_val"
      ],
      "metadata": {
        "id": "DMroWb_RPGkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_set= pd.DataFrame.from_dict({'Image Tag':tags_train, 'Image Route': train_mel+train_bcc+train_scc, 'Label': X_train})\n",
        "valid_set= pd.DataFrame.from_dict({'Image Tag':tags_val, 'Image Route': train_mel_val+train_bcc_val+train_scc_val, 'Label': X_test})"
      ],
      "metadata": {
        "id": "NbP_tPVrPIdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_data= training_set['Image Route'].to_numpy()\n",
        "# y_train_data= training_set['Label'].to_numpy()\n",
        "X_test_data= valid_set['Image Route'].to_numpy()\n",
        "y_test_data= valid_set['Label'].to_numpy()"
      ],
      "metadata": {
        "id": "Wunwf5U2hbnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train,y_train = shuffle(X_train_data,y_train_data, random_state= 42)\n",
        "X_test,y_test= shuffle(X_test_data, y_test_data, random_state=42)"
      ],
      "metadata": {
        "id": "LcIw88jeSFsR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}